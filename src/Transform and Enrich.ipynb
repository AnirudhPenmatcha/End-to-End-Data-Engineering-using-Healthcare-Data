{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51121680-3d12-4459-9975-22a645f16629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Users/anirudhp@megnity.com/healthcare_project/src/Explore and Clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4424c47f-1d0a-4364-910f-4d983e4ef069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "first_camp_cleaned.printSchema()\n",
    "second_camp_cleaned.printSchema()\n",
    "third_camp_cleaned.printSchema()\n",
    "patient_profiles_cleaned.printSchema()\n",
    "health_camp_details_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef86ee8b-27e5-4e73-b20f-41a1b26aa089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. There are 5 tables. See if there is any relationship between them. \n",
    "2. If there is a relationship, check if it makes sense to put the related tables together in whichever way it can be required for end user usecase\n",
    "3. If needed, create new calculated or derived field if needed\n",
    "4. The end outcome could be unified table or tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0193315-bee4-4bf7-bb0f-2f0b244be872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### One unified table that can be created is combining all patient details from first_camp, second_camp, third_camp, and patient_profiles into one table. This can serve as on cosolidated table with all patient details. However, at the end, we will still save all tables as they can still be useful for specific analysis scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e1a582-aaea-4acd-b351-51ae83202ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Get all patient ids along with all the healthcamps they've attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47a98286-976c-4bc7-95ea-0b6a12c8fe66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Select and rename Health_Camp_ID columns\n",
    "try:\n",
    "    # Select only Patient_ID and Health_Camp_ID, renaming Health_Camp_ID for clarity\n",
    "    df_first_selected = first_camp_cleaned.select(\n",
    "        col(\"Patient_ID\"),\n",
    "        col(\"Health_Camp_ID\").alias(\"First_Camp_Health_ID\")\n",
    "    )\n",
    "    df_second_selected = second_camp_cleaned.select(\n",
    "        col(\"Patient_ID\"),\n",
    "        col(\"Health_Camp_ID\").alias(\"Second_Camp_Health_ID\")\n",
    "    )\n",
    "    df_third_selected = third_camp_cleaned.select(\n",
    "        col(\"Patient_ID\"),\n",
    "        col(\"Health_Camp_ID\").alias(\"Third_Camp_Health_ID\")\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error selecting columns: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 2: Perform outer joins to combine all Patient_IDs\n",
    "try:\n",
    "    # Join the three DataFrames on Patient_ID using outer joins\n",
    "    all_patients = df_first_selected.join(\n",
    "        df_second_selected,\n",
    "        \"Patient_ID\",\n",
    "        \"outer\"\n",
    "    ).join(\n",
    "        df_third_selected,\n",
    "        \"Patient_ID\",\n",
    "        \"outer\"\n",
    "    )\n",
    "    print(\"DataFrames joined successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error joining DataFrames: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 3: Display sample output (first 10 rows)\n",
    "display(all_patients.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec3a905-c438-486b-b1e7-a1dcc34c8fb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Perform an outer join of all_patients with patient_profiles details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf15df8-d462-411f-8269-6adef4a1a67b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform a left join of all_patient_details with patient_profiles on Patient_ID\n",
    "all_patient_details = all_patients.join(patient_profiles, \"Patient_ID\", \"left\")\n",
    "\n",
    "# Display the first 25 rows of the final DataFrame\n",
    "display(all_patient_details.limit(25))\n",
    "\n",
    "# Print schema and row count\n",
    "all_patient_details.printSchema()\n",
    "print(f\"Row count: {all_patient_details.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90404ade-0845-4bcb-9e3c-f27117c28588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Combine all_patient_details table with all the information we have on them from the health_camp tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3656b1f8-f756-4843-af38-4135e379de01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Combine donation and health_score from first_camp_cleaned with matching patient_ID in all_patient_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e8679d-a6e4-46ec-965f-72c618964f9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Perform an outer join with all_patient_details and first_camp_cleaned on Patient_ID and health_camp_id\n",
    "df_joined = all_patient_details.alias(\"df1\").join(\n",
    "    first_camp_cleaned.select(\n",
    "        col(\"patient_id\").alias(\"Patient_ID\"),\n",
    "        col(\"health_camp_id\").alias(\"First_Camp_Health_ID\"),\n",
    "        \"donation\",\n",
    "        \"health_score\"\n",
    "    ).alias(\"df2\"),\n",
    "    on=[col(\"df1.Patient_ID\") == col(\"df2.Patient_ID\"), col(\"df1.First_Camp_Health_ID\") == col(\"df2.First_Camp_Health_ID\")],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Select only the required columns and rename health_score to first_camp_health_score\n",
    "all_patient_details_updated = df_joined.select(\n",
    "    col(\"df1.*\"),\n",
    "    col(\"df2.donation\"),\n",
    "    col(\"df2.health_score\").alias(\"first_camp_health_score\")\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "display(all_patient_details_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a7fb0e-3ab2-4448-91c6-57a61a5ada37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Now add health score from the second table to all_patient_details_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4953d71-dcc8-4ae8-abb8-4d04409981a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Perform an outer join with all_patient_details_updated and second_camp_cleaned on Patient_ID and health_camp_id\n",
    "df_joined_second = all_patient_details_updated.alias(\"df1\").join(\n",
    "    second_camp_cleaned.select(\n",
    "        col(\"patient_id\").alias(\"Patient_ID\"),\n",
    "        col(\"health_camp_id\").alias(\"Second_Camp_Health_ID\"),\n",
    "        col(\"health_score\").alias(\"second_camp_health_score\")\n",
    "    ).alias(\"df2\"),\n",
    "    on=[col(\"df1.Patient_ID\") == col(\"df2.Patient_ID\"), col(\"df1.Second_Camp_Health_ID\") == col(\"df2.Second_Camp_Health_ID\")],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Select only the required columns\n",
    "all_patient_details_updated = df_joined_second.select(\n",
    "    col(\"df1.*\"),\n",
    "    col(\"df2.second_camp_health_score\")\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "display(all_patient_details_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c938c10-ec31-4c6b-929a-7577f144a47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Combine the remaining information from the third table into the all_patient_details_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9048ce24-9549-435a-9060-82830bc41574",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1752003430450}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform an outer join with all_patient_details_updated and third_camp_cleaned on Patient_ID and health_camp_id\n",
    "df_joined_third = all_patient_details_updated.alias(\"df1\").join(\n",
    "    third_camp_cleaned.select(\n",
    "        col(\"patient_id\").alias(\"Patient_ID\"),\n",
    "        col(\"health_camp_id\").alias(\"Third_Camp_Health_ID\"),\n",
    "        col(\"number_of_stall_visited\"),\n",
    "        col(\"last_stall_visited_number\")\n",
    "    ).alias(\"df2\"),\n",
    "    on=[col(\"df1.Patient_ID\") == col(\"df2.Patient_ID\"), col(\"df1.Third_Camp_Health_ID\") == col(\"df2.Third_Camp_Health_ID\")],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Select only the required columns\n",
    "all_patient_details_updated = df_joined_third.select(\n",
    "    col(\"df1.*\"),\n",
    "    col(\"df2.number_of_stall_visited\").alias(\"number_of_stall_visited_in_third_camp\"),\n",
    "    col(\"df2.last_stall_visited_number\").alias(\"last_stall_visited_number_in_third_camp\")\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "display(all_patient_details_updated)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6191188712914425,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Transform and Enrich",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
